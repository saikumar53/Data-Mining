{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_features(file_name):\n",
    "    data = pd.read_csv(file_name, header = None)\n",
    "    data = data.drop(data.columns[0], axis=1)\n",
    "    return data\n",
    "\n",
    "def get_test_features(file_name):\n",
    "    data = pd.read_csv(file_name, header = None)\n",
    "    indexes  = data.iloc[:,0]\n",
    "    data = data.drop(data.columns[0], axis=1)\n",
    "    return indexes, data\n",
    "\n",
    "def get_labels(file_name):\n",
    "    data = pd.read_csv(file_name)\n",
    "    data = data.drop(data.columns[0], axis=1)\n",
    "    return data.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and Normalizing the data\n",
    "train_features_file = \"train_features.csv\"\n",
    "train_features = get_train_features(train_features_file)\n",
    "train_features = preprocessing.normalize(train_features)\n",
    "\n",
    "train_label_file = \"train_labels.csv\"\n",
    "train_labels = get_labels(train_label_file)\n",
    "\n",
    "test_features_file = \"test_features.csv\"\n",
    "indexes, test_features = get_test_features(test_features_file)\n",
    "test_features = preprocessing.normalize(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of Confusion Matrix\n",
    "def confusion_matrix(original, predicted):\n",
    "    accuracy = precision = recall = f_measure = 0\n",
    "    TP = FN = FP = TN = 0\n",
    "    for i in range(len(original)):\n",
    "        if original[i] == 1 and predicted[i] == 1:\n",
    "            TP += 1\n",
    "        elif original[i] == 1 and predicted[i] == 0:\n",
    "            FN += 1\n",
    "        elif original[i] == 0 and predicted[i] == 1:\n",
    "            FP += 1\n",
    "        else:\n",
    "            TN += 1\n",
    "            \n",
    "    accuracy = (float(TP + TN)/(TP + FN + FP + TN))\n",
    "    f_measure = (float(2 * TP) / ((2 * TP) + FN + FP))\n",
    "            \n",
    "    return accuracy, f_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training and validation sets for Knn : 69.0\n",
      "F1-score for training and validation sets for Knn : 80.98159509202453\n"
     ]
    }
   ],
   "source": [
    "#K nearest neighbors\n",
    "string = \"knn\"\n",
    "knn = KNeighborsClassifier(n_neighbors=13)\n",
    "\n",
    "#Train and Test Validation Accuracy\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_labels, test_size=0.25, random_state=1)\n",
    "Y_knn_pred = knn.fit(X_train,y_train).predict(X_val)\n",
    "acc_knn,f1_knn = confusion_matrix(y_val,Y_knn_pred)\n",
    "print('Accuracy for training and validation sets for Knn : '+ str(acc_knn * 100))\n",
    "print('F1-score for training and validation sets for Knn : '+ str(f1_knn * 100))\n",
    "\n",
    "\n",
    "#Test Submission\n",
    "Y_knn = knn.fit(train_features,train_labels).predict(test_features)\n",
    "final_df = pd.concat([pd.DataFrame(indexes), pd.DataFrame(Y_knn)], axis=1)\n",
    "final_df.columns=[\"id\",\"label\"]\n",
    "final_df.to_csv(string+\"_accuracy.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training and validation sets for Bagging : 75.0\n",
      "F1-score for training and validation sets for Bagging : 82.75862068965517\n"
     ]
    }
   ],
   "source": [
    "#Bagging\n",
    "string = \"bagging\"\n",
    "bag = BaggingClassifier(n_estimators=8, max_samples=1.0, max_features=1.0)\n",
    "\n",
    "#Train and Validation Accuracy\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_labels, test_size=0.25, random_state=1)\n",
    "Y_bag_pred = bag.fit(X_train,y_train).predict(X_val)\n",
    "acc_bag,f1_bag = confusion_matrix(y_val,Y_bag_pred)\n",
    "print('Accuracy for training and validation sets for Bagging : '+ str(acc_bag * 100))\n",
    "print('F1-score for training and validation sets for Bagging : '+ str(f1_bag * 100))\n",
    "\n",
    "#Test Submission\n",
    "Y_bag = bag.fit(train_features,train_labels).predict(test_features)\n",
    "final_df = pd.concat([pd.DataFrame(indexes), pd.DataFrame(Y_bag)], axis=1)\n",
    "final_df.columns=[\"id\",\"label\"]\n",
    "final_df.to_csv(string+\"_accuracy.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training and validation sets for decision tree : 77.0\n",
      "F1-score for training and validation sets for decision tree : 84.35374149659864\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "string = \"decision_tree\"\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion = 'gini')\n",
    "\n",
    "#Train and Test Validation Accuracy\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_labels, test_size=0.25, random_state=1)\n",
    "Y_dt_pred = tree.fit(X_train,y_train).predict(X_val)\n",
    "acc_dt,f1_dt = confusion_matrix(y_val,Y_dt_pred)\n",
    "print('Accuracy for training and validation sets for decision tree : '+ str(acc_dt * 100))\n",
    "print('F1-score for training and validation sets for decision tree : '+ str(f1_dt * 100))\n",
    "\n",
    "#Test Submission\n",
    "Y_dt = tree.fit(train_features,train_labels).predict(test_features)\n",
    "final_df = pd.concat([pd.DataFrame(indexes), pd.DataFrame(Y_dt)], axis=1)\n",
    "final_df.columns=[\"id\",\"label\"]\n",
    "final_df.to_csv(string+\"_accuracy.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training and validation sets for random forest : 77.0\n",
      "F1-score for training and validation sets for random forest : 85.16129032258064\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "string = \"Random_Forest\"\n",
    "\n",
    "rfc = RandomForestClassifier(criterion='gini', n_estimators = 10) \n",
    "\n",
    "#Train and Test Validation Accuracy\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_labels, test_size=0.25, random_state=1)\n",
    "Y_rf_pred = rfc.fit(X_train,y_train).predict(X_val)\n",
    "acc_rf,f1_rf = confusion_matrix(y_val,Y_rf_pred)\n",
    "print('Accuracy for training and validation sets for random forest : '+ str(acc_rf * 100))\n",
    "print('F1-score for training and validation sets for random forest : '+ str(f1_rf * 100))\n",
    "\n",
    "#Test Submission\n",
    "Y_rf = rfc.fit(train_features,train_labels).predict(test_features)\n",
    "final_df = pd.concat([pd.DataFrame(indexes), pd.DataFrame(Y_rf)], axis=1)\n",
    "final_df.columns=[\"id\",\"label\"]\n",
    "final_df.to_csv(string+\"_accuracy.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training and validation sets for Adaboost Classifier : 71.0\n",
      "F1-score for training and validation sets for Adaboost Classifier : 83.04093567251462\n"
     ]
    }
   ],
   "source": [
    "#Adaboost Classifier\n",
    "string = \"AdaBoost\"\n",
    "AdBC= AdaBoostClassifier(n_estimators=5, learning_rate=0.2)\n",
    "# Y_adbc = AdBC.fit(train_features,train_labels).predict(test_features)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_labels, test_size=0.25, random_state=1)\n",
    "Y_adbc_pred = AdBC.fit(X_train,y_train).predict(X_val)\n",
    "acc_adbc,f1_adbc = confusion_matrix(y_val,Y_adbc_pred)\n",
    "print('Accuracy for training and validation sets for Adaboost Classifier : '+ str(acc_adbc * 100))\n",
    "print('F1-score for training and validation sets for Adaboost Classifier : '+ str(f1_adbc * 100))\n",
    "\n",
    "Y_adbc = AdBC.fit(train_features,train_labels).predict(test_features)\n",
    "final_df = pd.concat([pd.DataFrame(indexes), pd.DataFrame(Y_adbc)], axis=1)\n",
    "final_df.columns=[\"id\",\"label\"]\n",
    "final_df.to_csv(string+\"_accuracy.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training and validation sets for Grid Search : 75.0\n",
      "F1-score for training and validation sets for Grid Search : 83.44370860927152\n"
     ]
    }
   ],
   "source": [
    "#GridSearchAdaboost with varied number of estimators and learning rates\n",
    "string = 'GridSearch_Adaboost'\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 50, 100, 500]\n",
    "grid['learning_rate'] = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "model = AdaBoostClassifier()\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy')\n",
    "\n",
    "#Train and Validation Accuracy\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_labels, test_size=0.25, random_state=1)\n",
    "model = grid_search.fit(X_train, y_train)\n",
    "y_pred_val = model.predict(X_val)\n",
    "acc_grid,f1_grid = confusion_matrix(y_val,y_pred_val)\n",
    "print('Accuracy for training and validation sets for Grid Search : '+ str(acc_grid * 100))\n",
    "print('F1-score for training and validation sets for Grid Search : '+ str(f1_grid * 100))\n",
    "\n",
    "#Test Submission\n",
    "y_pred = grid_search.fit(train_features,train_labels).predict(test_features)\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred['id'] = y_pred.index\n",
    "y_pred['label'] = y_pred[0]\n",
    "del y_pred[0]\n",
    "y_pred.to_csv(string+'_predicted_labels.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training and validation sets for Adaboost Regressor : 78.0\n",
      "F1-score for training and validation sets for Adaboost Regressor : 84.93150684931507\n"
     ]
    }
   ],
   "source": [
    "#Multiple Adaboost Regressors \n",
    "def get_value(predicted):\n",
    "    res1 = []\n",
    "    for i1 in Y1:\n",
    "        _ = res1.append(1) if i1 >= 0.5 else res1.append(0)\n",
    "    return res1\n",
    "\n",
    "string = \"AdaBoostRegressor\"\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_labels, test_size=0.25, random_state=1)\n",
    "\n",
    "AdbcR1  = AdaBoostRegressor(n_estimators =1300,loss='exponential',learning_rate=1)\n",
    "# Y1 = AdbcR1.fit(train_features,train_labels).predict(test_features)\n",
    "# Y1 = get_value(Y1)\n",
    "\n",
    "Y1 = AdbcR1.fit(X_train,y_train).predict(X_val)\n",
    "Y1 = get_value(Y1)\n",
    "    \n",
    "AdbcR2  = AdaBoostRegressor(n_estimators =1300,loss='square',learning_rate=1)\n",
    "# Y2 = AdbcR2.fit(train_features,train_labels).predict(test_features)\n",
    "# Y2 = get_value(Y2)\n",
    "\n",
    "Y2 = AdbcR2.fit(X_train,y_train).predict(X_val)\n",
    "Y2 = get_value(Y2)\n",
    "\n",
    "\n",
    "y_ada_regress = []\n",
    "for x in range(len(Y1)):\n",
    "    zeroes = ones = 0\n",
    "    if(Y1[x] == 0):\n",
    "        zeroes += 1\n",
    "    else:\n",
    "        ones += 1\n",
    "\n",
    "    if(Y2[x] == 0):\n",
    "        zeroes += 1\n",
    "    else:\n",
    "        ones += 1\n",
    "        \n",
    "    _ = y_ada_regress.append(1) if ones > zeroes else y_ada_regress.append(0) \n",
    "    \n",
    "acc_adbcR,f1_adbcR = confusion_matrix(y_val,y_ada_regress)\n",
    "\n",
    "print('Accuracy for training and validation sets for Adaboost Regressor : '+ str(acc_adbcR * 100))\n",
    "print('F1-score for training and validation sets for Adaboost Regressor : '+ str(f1_adbcR * 100))\n",
    "\n",
    "final_df = pd.concat([pd.DataFrame(indexes), pd.DataFrame(y_ada_regress)], axis=1)\n",
    "final_df.columns=[\"id\",\"label\"]\n",
    "final_df.to_csv(string+\"_accuracy.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training and validation sets for Naive Bayes Bernoulli : 81.0\n",
      "F1-score for training and validation sets for Naive Bayes Bernoulli : 87.24832214765101\n"
     ]
    }
   ],
   "source": [
    "#NaiveBayes_bernoulli\n",
    "string = \"naivebayes_bernoulli\"\n",
    "\n",
    "nb = BernoulliNB(alpha = 1e-02, binarize=0.0, fit_prior=True, class_prior=None)\n",
    "\n",
    "#Train and Test Validation Accuracy\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_labels, test_size=0.25, random_state=1)\n",
    "Y_nb_pred = nb.fit(X_train,y_train).predict(X_val)\n",
    "acc_nb,f1_nb = confusion_matrix(y_val,Y_nb_pred)\n",
    "print('Accuracy for training and validation sets for Naive Bayes Bernoulli : '+ str(acc_nb * 100))\n",
    "print('F1-score for training and validation sets for Naive Bayes Bernoulli : '+ str(f1_nb * 100))\n",
    "\n",
    "#Test Submission\n",
    "Y_nb = nb.fit(train_features,train_labels).predict(test_features)\n",
    "final_df = pd.concat([pd.DataFrame(indexes), pd.DataFrame(Y_nb)], axis=1)\n",
    "final_df.columns=[\"id\",\"label\"]\n",
    "final_df.to_csv(string+\"_accuracy.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
