{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the categorical data\n",
    "def check_categorical(data):\n",
    "    categorical_index = []\n",
    "    for i,value in enumerate(data.dtypes):\n",
    "        if(value == 'object'):\n",
    "            categorical_index.append(i)\n",
    "    j = 0\n",
    "    data = data.to_numpy()\n",
    "    while j < len(categorical_index):\n",
    "        temp = data[:,categorical_index[j]]\n",
    "        u_categorical = np.unique(temp)\n",
    "        num_indexes = []\n",
    "        for i,value in enumerate(u_categorical):\n",
    "            num_indexes.append(i)\n",
    "        dictionary = dict(zip(u_categorical, num_indexes)) \n",
    "        for k in range(len(temp)):\n",
    "            data[k][categorical_index[j]] = dictionary.get(data[k][categorical_index[j]])\n",
    "        j+=1\n",
    "    \n",
    "    return data.astype(float),categorical_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of GINI Index\n",
    "def gini_helper(node):\n",
    "    score = 0.0\n",
    "    size = float(len(node))\n",
    "    zero = list(node[:,-1]).count(0)/float(len(node))\n",
    "    one = list(node[:,-1]).count(1) / float(len(node))\n",
    "    score += zero*zero \n",
    "    score+= one * one\n",
    "    return score\n",
    " \n",
    "def calc_gini_index(left_n,right_n):\n",
    "    gini_index, total = 0, float(len(left_n) + len(right_n))\n",
    "    if(len(left_n)):\n",
    "        l_score = gini_helper(left_n)\n",
    "        gini_index += (1.0 - l_score) * (float(len(left_n)) / total)\n",
    "    if(len(right_n)):\n",
    "        r_score = gini_helper(right_n)\n",
    "        gini_index += (1.0 - r_score) * (float(len(right_n)) / total)\n",
    "    \n",
    "    return gini_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset based on an attribute and an attribute value\n",
    "def split(train_dataset,split_value, index, categorical_index):\n",
    "    left = []\n",
    "    right = []\n",
    "    for r in train_dataset:\n",
    "        if index not in categorical_index:\n",
    "            _ = [left.append(r) if r[index] < split_value else right.append(r)]\n",
    "        else:\n",
    "            _ = [left.append(r) if r[index] == split_value else right.append(r)]\n",
    "    return left, right        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best split point for a dataset\n",
    "def split_node(train_dataset, categorical_index):\n",
    "    min_err = float('inf')\n",
    "    split_attr, left, right, split_value = 999,None,None,999\n",
    "    for index in range(train_dataset.shape[1]-1):\n",
    "        for row in train_dataset:\n",
    "            l, r = split(train_dataset, row[index], index,categorical_index)\n",
    "            l, r = np.asarray(l),np.asarray(r)\n",
    "            err = calc_gini_index(l,r)\n",
    "            if err < min_err:\n",
    "                min_err = err\n",
    "                left,right = l,r\n",
    "                split_attr,split_value = index, row[index]    \n",
    "    \n",
    "    return {'split_attr': split_attr, 'left':left, 'right':right, 'split_value':split_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Termninal Node\n",
    "def to_terminal(left_n,right_n):\n",
    "    ones = 0\n",
    "    zeroes = 0\n",
    "    \n",
    "    if(len(left_n)):\n",
    "        zeroes += list(left_n[:,-1]).count(0)\n",
    "        ones += list(left_n[:,-1]).count(1)\n",
    "    if(len(right_n)):\n",
    "        zeroes += list(right_n[:,-1]).count(0)\n",
    "        ones += list(right_n[:,-1]).count(1)\n",
    "    if(ones>zeroes):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#Build the decision tree from the root\n",
    "def build_tree(node,categorical_index):\n",
    "    l = node['left']\n",
    "    del(node['left'])\n",
    "    r = node['right']\n",
    "    del(node['right'])\n",
    "    \n",
    "    if len(l) == 0 or len(r) == 0:\n",
    "        node['left'] = node['right'] = to_terminal(l, r)\n",
    "        return node \n",
    "    if len(set(l[:,-1])) == 1:\n",
    "        node['left'] = to_terminal(l, [])\n",
    "    else:\n",
    "        node['left'] = build_tree(split_node(l,categorical_index),categorical_index)\n",
    "    if len(set(r[:,-1])) == 1:\n",
    "        node['right'] = to_terminal([], r)\n",
    "    else:\n",
    "        node['right'] = build_tree(split_node(r,categorical_index),categorical_index)\n",
    "    return node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classification\n",
    "def dt_classify(node, row):\n",
    "    if row[node['split_attr']] < node['split_value']:\n",
    "        if isinstance(node['left'],dict) == False:\n",
    "            return node['left']\n",
    "        else:\n",
    "            return dt_classify(node['left'] , row)    \n",
    "\n",
    "    if isinstance(node['right'],dict) == False:\n",
    "        return node['right']\n",
    "    else:\n",
    "        return dt_classify(node['right'] , row)  \n",
    "    \n",
    "#Calculation of Confusion Matrix\n",
    "def confusion_matrix(original, predicted):\n",
    "    accuracy = precision = recall = f_measure = 0\n",
    "    TP = FN = FP = TN = 0\n",
    "    for i in range(len(original)):\n",
    "        if original[i] == 1 and predicted[i] == 1:\n",
    "            TP += 1\n",
    "        elif original[i] == 1 and predicted[i] == 0:\n",
    "            FN += 1\n",
    "        elif original[i] == 0 and predicted[i] == 1:\n",
    "            FP += 1\n",
    "        else:\n",
    "            TN += 1\n",
    "            \n",
    "    if(TP + FN + FP + TN) != 0:\n",
    "        accuracy = (float(TP + TN)/(TP + FN + FP + TN))\n",
    "    if(TP + FP) != 0:\n",
    "        precision = (float(TP)/(TP + FP))\n",
    "    if(TP + FN)!= 0:\n",
    "        recall = (float(TP)/(TP + FN))\n",
    "    f_measure = (float(2 * TP) / ((2 * TP) + FN + FP))\n",
    "            \n",
    "    return accuracy, precision, recall, f_measure\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results for the file project3_dataset1.txt --------------\n",
      "Accuracy : 92.43421052631578\n",
      "Precision: 91.47086922452317\n",
      "Recall : 88.53501551356514\n",
      "F-1 Measure: 89.79424987236926\n"
     ]
    }
   ],
   "source": [
    "#Main Function\n",
    "def __main__():\n",
    "    accuracy = precision = recall = f_measure = 0\n",
    "    \n",
    "    #Load the file in a Data Frame\n",
    "    file = 'project3_dataset1.txt'\n",
    "    data = pd.read_csv(file,sep=\"\\t\", header=None)    \n",
    "    data = data.iloc[:,:data.shape[1]]\n",
    "    data, categorical_index = check_categorical(data)\n",
    "    \n",
    "    #Number of Folds\n",
    "    folds = np.array_split(data,10)\n",
    "    \n",
    "    #Number of loops\n",
    "    i=0\n",
    "    while(i<len(folds)):\n",
    "        #test_set\n",
    "        test = np.asarray(folds[i])\n",
    "        train = []\n",
    "        predicted_labels = []\n",
    "        for index,value in enumerate(folds):\n",
    "            if(index != i):\n",
    "                train.append(value)\n",
    "     \n",
    "        #train_set\n",
    "        train = np.asarray(np.vstack(train))\n",
    "        \n",
    "        \n",
    "        root = dict()\n",
    "        root = split_node(train,categorical_index)\n",
    "        root = build_tree(root,categorical_index)\n",
    "\n",
    "        \n",
    "        for item in range(len(test)):\n",
    "            test_point = test[item]\n",
    "            \n",
    "            #Classification and Predication of the points\n",
    "            final_class_labels = dt_classify(root, test_point)\n",
    "            predicted_labels.append(final_class_labels)\n",
    "            \n",
    "        #Accuracy, Precision, Recall, Precision calculations\n",
    "        acc, prec, rec, f_meas = confusion_matrix(test[:,-1], np.asarray(predicted_labels))\n",
    "        accuracy += acc\n",
    "        precision += prec\n",
    "        recall += rec\n",
    "        f_measure += f_meas\n",
    "        \n",
    "        i+=1\n",
    "    \n",
    "    #Outputs\n",
    "    print('Decision Tree Results for the file {} --------------'.format(file))\n",
    "    print('Accuracy : {}'.format(str(accuracy * 10)))\n",
    "    print('Precision: {}'.format(str(precision * 10)))\n",
    "    print('Recall : {}'.format(str(recall * 10)))\n",
    "    print('F-1 Measure: {}'.format(str(f_measure * 10)))\n",
    "        \n",
    "    \n",
    "__main__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
