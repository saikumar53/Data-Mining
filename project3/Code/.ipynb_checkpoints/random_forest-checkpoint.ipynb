{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the categorical data\n",
    "def check_categorical(data):\n",
    "    categorical_index = []\n",
    "    for i,value in enumerate(data.dtypes):\n",
    "        if(value == 'object'):\n",
    "            categorical_index.append(i)\n",
    "    j = 0\n",
    "    data = data.to_numpy()\n",
    "    while j < len(categorical_index):\n",
    "        temp = data[:,categorical_index[j]]\n",
    "        u_categorical = np.unique(temp)\n",
    "        num_indexes = []\n",
    "        for i,value in enumerate(u_categorical):\n",
    "            num_indexes.append(i)\n",
    "        dictionary = dict(zip(u_categorical, num_indexes))\n",
    "        for k in range(len(temp)):\n",
    "            data[k][categorical_index[j]] = dictionary.get(data[k][categorical_index[j]])\n",
    "        j+=1\n",
    "    \n",
    "    return data.astype(float),categorical_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of GINI Index\n",
    "def gini_helper(node):\n",
    "    score = 0.0\n",
    "    size = float(len(node))\n",
    "    zero = list(node[:,-1]).count(0)/float(len(node))\n",
    "    one = list(node[:,-1]).count(1) / float(len(node))\n",
    "    score += zero*zero \n",
    "    score+= one * one\n",
    "    return score\n",
    " \n",
    "def calc_gini_index(left_n,right_n):\n",
    "    gini_index, total = 0, float(len(left_n) + len(right_n))\n",
    "    if(len(left_n)):\n",
    "        l_score = gini_helper(left_n)\n",
    "        gini_index += (1.0 - l_score) * (float(len(left_n)) / total)\n",
    "    if(len(right_n)):\n",
    "        r_score = gini_helper(right_n)\n",
    "        gini_index += (1.0 - r_score) * (float(len(right_n)) / total)\n",
    "    \n",
    "    return gini_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset based on an attribute and an attribute value\n",
    "def split(train_dataset,split_value, index, categorical_index):\n",
    "    left = []\n",
    "    right = []\n",
    "    for r in train_dataset:\n",
    "        if index not in categorical_index:\n",
    "            _ = [left.append(r) if r[index] < split_value else right.append(r)]\n",
    "        else:\n",
    "            _ = [left.append(r) if r[index] == split_value else right.append(r)]\n",
    "    return left, right        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best split point for a dataset\n",
    "def split_node(train_dataset, categorical_index ,num_rand_features):\n",
    "    min_err = float('inf')\n",
    "    split_attr, left, right, split_value = 999,None,None,999\n",
    "    \n",
    "    train_cols = [i for i in range(train_dataset.shape[1]-1)]\n",
    "    columns = random.sample(train_cols , num_rand_features )\n",
    "    \n",
    "    for index in columns:\n",
    "        for row in train_dataset:\n",
    "            l, r = split(train_dataset, row[index], index,categorical_index)\n",
    "            l, r = np.asarray(l),np.asarray(r)\n",
    "            err = calc_gini_index(l,r)\n",
    "            if err < min_err:\n",
    "                min_err = err\n",
    "                left,right = l,r\n",
    "                split_attr,split_value = index, row[index]    \n",
    "    \n",
    "    return {'split_attr': split_attr, 'left':left, 'right':right, 'split_value':split_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Termninal Node\n",
    "def to_terminal(left_n,right_n):\n",
    "    ones = 0\n",
    "    zeroes = 0\n",
    "    \n",
    "    if(len(left_n)):\n",
    "        zeroes += list(left_n[:,-1]).count(0)\n",
    "        ones += list(left_n[:,-1]).count(1)\n",
    "    if(len(right_n)):\n",
    "        zeroes += list(right_n[:,-1]).count(0)\n",
    "        ones += list(right_n[:,-1]).count(1)\n",
    "    if(ones>zeroes):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#Build the decision tree from the root\n",
    "def build_tree(node,categorical_index,num_rand_features):\n",
    "    l = node['left']\n",
    "    del(node['left'])\n",
    "    r = node['right']\n",
    "    del(node['right'])\n",
    "    \n",
    "    if len(l) == 0 or len(r) == 0:\n",
    "        node['left'] = node['right'] = to_terminal(l, r)\n",
    "        return node \n",
    "    if len(set(l[:,-1])) == 1:\n",
    "        node['left'] = to_terminal(l, [])\n",
    "    else:\n",
    "        node['left'] = build_tree(split_node(l,categorical_index,num_rand_features),categorical_index,num_rand_features)\n",
    "    if len(set(r[:,-1])) == 1:\n",
    "        node['right'] = to_terminal([], r)\n",
    "    else:\n",
    "        node['right'] = build_tree(split_node(r,categorical_index,num_rand_features),categorical_index,num_rand_features)\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classification\n",
    "def dt_classify(node, row):\n",
    "    if row[node['split_attr']] < node['split_value']:\n",
    "        if isinstance(node['left'],dict) == False:\n",
    "            return node['left']\n",
    "        else:\n",
    "            return dt_classify(node['left'] , row)    \n",
    "\n",
    "    if isinstance(node['right'],dict) == False:\n",
    "        return node['right']\n",
    "    else:\n",
    "        return dt_classify(node['right'] , row)  \n",
    "    \n",
    "#Calculation of Confusion Matrix\n",
    "def confusion_matrix(original, predicted):\n",
    "    accuracy = precision = recall = f_measure = 0\n",
    "    TP = FN = FP = TN = 0\n",
    "    for i in range(len(original)):\n",
    "        if original[i] == 1 and predicted[i] == 1:\n",
    "            TP += 1\n",
    "        elif original[i] == 1 and predicted[i] == 0:\n",
    "            FN += 1\n",
    "        elif original[i] == 0 and predicted[i] == 1:\n",
    "            FP += 1\n",
    "        else:\n",
    "            TN += 1\n",
    "            \n",
    "    accuracy = (float(TP + TN)/(TP + FN + FP + TN))\n",
    "    if(TP + FP) != 0:\n",
    "        precision = (float(TP)/(TP + FP))\n",
    "    if(TP + FN)!= 0:\n",
    "        recall = (float(TP)/(TP + FN))\n",
    "    f_measure = (float(2 * TP) / ((2 * TP) + FN + FP))\n",
    "            \n",
    "    return accuracy, precision, recall, f_measure\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Implementation\n",
    "def randForest(train_dataset,test_dataset,categorical_index,num_trees,num_rand_features):\n",
    "    final_test_class,predicted_labels = list(),defaultdict(list)\n",
    "    for tree in range(num_trees):\n",
    "        sample = train_dataset[np.random.choice(len(train_dataset), len(train_dataset), replace=True),:]\n",
    "        root = split_node(train_dataset, categorical_index, num_rand_features)\n",
    "        root = build_tree(root,categorical_index,num_rand_features)\n",
    "        \n",
    "        for item in range(len(test_dataset)):\n",
    "            test_point = test_dataset[item]\n",
    "            predicted_labels[item].append(dt_classify(root,test_point))\n",
    "            \n",
    "    for key in predicted_labels:\n",
    "        final_test_class.append(max(set(predicted_labels[key]) , key=predicted_labels[key].count))\n",
    "    return final_test_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of trees : 4\n",
      "Enter the number of features to split : 2\n",
      "Random Forest Results for the file project3_dataset1.txt --------------\n",
      "Accuracy : 94.72431077694236\n",
      "Precision: 98.27164502164501\n",
      "Recall : 87.84016879025542\n",
      "F-1 Measure: 92.70114422165656\n"
     ]
    }
   ],
   "source": [
    "#Main Function\n",
    "def __main__():\n",
    "    accuracy = precision = recall = f_measure = 0\n",
    "    \n",
    "    #Load the file in a Data Frame\n",
    "    file = 'project3_dataset1.txt'\n",
    "    data = pd.read_csv(file,sep=\"\\t\", header=None)    \n",
    "    data = data.iloc[:,:data.shape[1]]\n",
    "    data, categorical_index = check_categorical(data)\n",
    "    \n",
    "    #Number of Folds\n",
    "    folds = np.array_split(data,10)\n",
    "    \n",
    "    #Looping through the folds\n",
    "    num_trees = int(input('Enter the number of trees : '))\n",
    "    num_rand_features = int(input('Enter the number of features to split : '))\n",
    "#     num_rand_features = int(len(data[0]) / 5)\n",
    "    \n",
    "    \n",
    "    #Looping through the folds\n",
    "    i=0\n",
    "    while(i<len(folds)):\n",
    "        #test_set\n",
    "        test = np.asarray(folds[i])\n",
    "        train = []\n",
    "        predicted_labels = []\n",
    "        for index,value in enumerate(folds):\n",
    "            if(index != i):\n",
    "                train.append(value)\n",
    "                \n",
    "        #train_set\n",
    "        train = np.asarray(np.vstack(train))\n",
    "        \n",
    "        #Prediciton of labels using Random Forest\n",
    "        predicted_labels = randForest(train,test,categorical_index,num_trees,num_rand_features)\n",
    "            \n",
    "        #Accuracy, Precision, Recall, Precision calculations\n",
    "        acc, prec, rec, f_meas = confusion_matrix(test[:,-1], np.asarray(predicted_labels))\n",
    "        accuracy += acc\n",
    "        precision += prec\n",
    "        recall += rec\n",
    "        f_measure += f_meas\n",
    "        \n",
    "        i+=1\n",
    "    \n",
    "    #Outputs\n",
    "    print('Random Forest Results for the file {} --------------'.format(file))\n",
    "    print('Accuracy : {}'.format(str(accuracy * 10)))\n",
    "    print('Precision: {}'.format(str(precision * 10)))\n",
    "    print('Recall : {}'.format(str(recall * 10)))\n",
    "    print('F-1 Measure: {}'.format(str(f_measure * 10)))\n",
    "        \n",
    "    \n",
    "__main__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
